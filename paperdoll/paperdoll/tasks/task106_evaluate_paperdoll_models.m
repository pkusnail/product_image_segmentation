function task106_evaluate_paperdoll_models
%TASK106_EVALUATE_PAPERDOLL_MODELS
  fashionista_file = 'data/fashionista_v0.2.mat';
  pipeline_file = 'data/paperdoll_pipeline.mat';
  samples = load_fashionista_samples(fashionista_file);
  config = load_evaluation_pipeline(pipeline_file);
  samples = feature_calculator.apply(config, samples);
  evaluations = aggregate_evaluations(samples);
  print_evaluation(evaluations);
  save tmp/task106_evaluations.mat evaluations samples;
end

function samples = load_fashionista_samples(fashionista_file)
%LOAD_FASHIONISTA_SAMPLES
  logger('Loading Fashionista dataset.');
  load(fashionista_file, 'truths', 'predictions', 'test_index');
  truths = truths(test_index);
  predictions = predictions(test_index);
  samples = struct(...
    'id', {truths.id}, ...
    'image', {truths.image}, ...
    'clothing_labels', cell(size(truths)), ...
    'clothing_annotation', cell(size(truths)), ...
    'cvpr2011_labeling', cell(size(truths)) ...
    ...'is_test', num2cell(test_index) ...
    );
  for i = 1:numel(samples)
    segmentation = imdecode(truths(i).annotation.superpixel_map);
    annotation = truths(i).annotation.superpixel_labels(segmentation);
    samples(i).clothing_labels = truths(i).annotation.labels;
    samples(i).clothing_annotation = imencode(uint8(annotation));
    segmentation = imdecode(predictions(i).annotation.superpixel_map);
    labeling = predictions(i).annotation.superpixel_labels(segmentation);
    samples(i).cvpr2011_labeling = imencode(uint8(labeling));
  end
end

function config = load_evaluation_pipeline(pipeline_file)
%LOAD_EVALUATION_PIPELINE
  logger('Loading evaluation pipeline.');
  load(pipeline_file, 'config');
  additional_calculators = {...
    labeling_extractor.create(...
      'Input', {...
        'clothing_localization', ...
        'exemplar_localization', ...
        'softmask_transfer', ...
        'combined_localization' ...
      }, ...
      'Output', {...
        'global_labeling', ...
        'exemplar_labeling', ...
        'softmask_labeling', ...
        'combined_labeling' ...
      } ...
    ), ...
    inverse_warp_calculator.create(...
      'InputImage', {...
        'global_labeling', ...
        'exemplar_labeling', ...
        'softmask_labeling', ...
        'combined_labeling', ...
        'refined_labeling'...
      }, ...
      'Output', {
        'global_labeling', ...
        'exemplar_labeling', ...
        'softmask_labeling', ...
        'combined_labeling', ...
        'refined_labeling'...
      } ...
    ), ...
    labeling_evaluator.create(),...
    field_extractor.create(...
      'Output', {...
        'id', ...
        'image', ...
        'pose', ...
        'clothing_labels', ...
        'clothing_annotation', ...
        'cvpr2011_labeling', ...
        'knn_predicted_labels', ...
        'knn_retrieved_ids', ...
        'global_labeling', ...
        'exemplar_labeling', ...
        'softmask_labeling', ...
        'combined_labeling', ...
        'refined_labeling', ...
        'evaluation' ...
      } ...
    ) ...
  };
  % Change the pose estimator threshold.
  config{1}.model.thresh = -2;
  config = [config(1:end-2), additional_calculators];
end

function output = aggregate_evaluations(samples)
%AGGREGATE_EVALUATIONS
  evaluations = cat(1, samples.evaluation);
  output = cell(1, size(evaluations, 2));
  for i = 1:size(evaluations, 2)
    confusion_matrix = sum(cat(3, evaluations(:, i).confusion_matrix), 3);
    evaluation.name = evaluations(1, i).name;
    evaluation.labels = samples(1).clothing_labels;
    evaluation.confusion_matrix = confusion_matrix;
    evaluation.accuracy = sum(diag(confusion_matrix)) / sum(confusion_matrix(:));
    evaluation.fg_accuracy = sum(diag(confusion_matrix(2:end,2:end))) / ...
                             sum(sum(confusion_matrix(2:end,:)));
    evaluation.precision = diag(confusion_matrix)' ./ sum(confusion_matrix, 1);
    evaluation.recall = diag(confusion_matrix)' ./ sum(confusion_matrix, 2)';
    evaluation.f1 = 2 * diag(confusion_matrix)' ./ ...
                    (sum(confusion_matrix, 1) + sum(confusion_matrix, 2)');
    evaluation.average_precision = mean(evaluation.precision(~isnan(evaluation.precision)));
    evaluation.average_recall = mean(evaluation.recall(~isnan(evaluation.recall)));
    evaluation.average_f1 = mean(evaluation.f1(~isnan(evaluation.f1)));
    output{i} = evaluation;
  end
  output = cat(2, output{:});
end

function print_evaluation(evaluations)
%PRINT_EVALUATION
  fields = {'accuracy', 'fg_accuracy', 'average_precision', ...
            'average_recall', 'average_f1'};
  for j = 1:numel(evaluations)
    fprintf('Method%d = %s\n', j, evaluations(j).name);
  end
  fprintf('%20s', '');
  for j = 1:numel(evaluations)
    fprintf(' Method%d', j);
  end
  fprintf('\n');
  for i = 1:numel(fields)
    fprintf('%20s', fields{i});
    for j = 1:numel(evaluations)
      fprintf('%8.4f', evaluations(j).(fields{i}));
    end
    fprintf('\n');
  end
end